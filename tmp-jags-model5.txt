
# standardize x and y into zx and zy
data {
    N <- length(y)
    mx <- mean(x)
    my <- mean(y)
    sdx <- sd(x)
    sdy <- sd(y)
    for (i in 1:length(y)) {
        zx[i] <- (x[i] - mx) / sdx
        zy[i] <- (y[i] - my) / sdy
    }
}

model {
    # likelihood
    for (i in 1:N) {
        zy[i]  ~ dnorm(mu[i], 1/zsigma^2)
        zxn[i] ~ dnorm(zx[i], 1/zsigma^2)
        mu[i] <- zbeta0 + zbeta1 * zxn[i] + zbeta2 * pow(zxn[i], 2)
    }
    
    # priors - these are all vague prior on standardized scale
    zbeta0 ~ dnorm( 0, 1/(10)^2 )
    zbeta1 ~ dnorm( 0, 1/(10)^2 )
    zbeta2 ~ dnorm( 0, 1/(10)^2 )
    zsigma ~ dunif( 1.0E-3, 1.0E+3)

    # transform to original scale. Algebra solved by Mathematica
    beta2 <- sdy * zbeta2 / pow(sdx, 2)
    beta1 <- sdy * (sdx * zbeta1 - 2 * mx * zbeta2) / pow(sdx, 2)
    beta0 <- my + sdy * (pow(sdx, 2) * zbeta0 - mx * sdx * zbeta1 + pow(mx, 2) * zbeta2)/pow(sdx, 2)
    sigma <- zsigma * sdy
}

